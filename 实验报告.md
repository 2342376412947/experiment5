
# <font face="黑体" size=12><center>实验报告：基于 LeNet-5 的 MNIST 手写数字识别</center></font>


#### 一、实验目的
1.掌握卷积神经网络的核心结构和卷积层、池化层、全连接层的工作原理及搭建方法

2.验证 CNN 在手写数字识别任务中的有效性，观察卷积层特征映射的可视化结果

3.实现 LeNet-5 模型的搭建、训练与测试流程

#### 二、实验原理
1.LeNet-5 是经典的卷积神经网络，核心结构包含卷积层、池化层和全连接层。

其中卷积层通过卷积核与输入图像做互相关运算，提取局部特征，本实验使用 2 层卷积层，分别输出 6 通道和 16 通道特征。

池化层采用平均池化，对卷积输出特征图降维，保留关键特征的同时减少计算量，池化核大小为 2×2，步长为 2。

激活函数使用 Sigmoid 函数引入非线性，提升模型拟合能力。

全连接层将卷积池化后的特征展平，通过全连接层实现分类，最终输出 10 维结果

2.本次实验的训练与优化是通过采用交叉熵损失，衡量模型预测结果与真实标签的差异，通过loss和acc来反映测试结果和训练效果

#### 三、实验环境

操作系统：Windows 11

软件环境：Anaconda 2023.09、Jupyter Notebook、Python 3.9 、torchvision 0.15+ 、Matplotlib 3.5+


#### 四、实验步骤

##### 1.数据集准备

通过torchvision 加载 MNIST 手写数字数据集，并做张量转换预处理和批量下载：
```python
#%%
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
import torch.nn.functional as F
import matplotlib.pyplot as plt

batch_size = 512
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

trainloader = torch.utils.data.DataLoader(
    datasets.MNIST('data', train=True, download=True,
                   transform=transforms.Compose([transforms.ToTensor()])),
    batch_size=batch_size, shuffle=True
)

testloader = torch.utils.data.DataLoader(
    datasets.MNIST('data', train=False, download=True,
                   transform=transforms.Compose([transforms.ToTensor()])),
    batch_size=batch_size, shuffle=True
)

```

##### 2.补全模型

实现 LeNet-5 网络结构，补全卷积层、全连接层定义及前向传播逻辑：

卷积层、全连接层：

```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5)    # 输入1通道，输出6通道，5x5卷积核
        self.conv2 = nn.Conv2d(6, 16, 5)   # 输入6通道，输出16通道，5x5卷积核
        self.fc1 = nn.Linear(4*4*16, 120)     # 原文档中存在错误错误是5*5*16=400 fc1的输入维度应为4*4*16=256
        self.fc2 = nn.Linear(120, 84)  #全连接层,输入120,输出84      
        self.clf = nn.Linear(84, 10)   #分类层,输入84,输出10
```

前向传播逻辑：

 ```python
def forward(self, x):
        #conv1
        #激活函数sigmoid()
        #平均池化层,kernel=2x2,步长2
        x = self.conv1(x)
        x = F.sigmoid(x)
        x = F.avg_pool2d(x, kernel_size=2, stride=2)  # 28→24→12

        #conv2
        #激活函数sigmoid()
        #平均池化层,2x2,步长2
        x = self.conv2(x)
        x = F.sigmoid(x)
        x = F.avg_pool2d(x, kernel_size=2, stride=2)  # 12→8→4

         #展平,从第1维开始展平
        x = x.view(x.size(0), -1)
        
        #全连接层1
        #激活函数sigmoid()
        #全连接层2
        #激活函数sigmoid()
        #分类层
        x = self.fc1(x)
        x = F.sigmoid(x)
        x = self.fc2(x)
        x = F.sigmoid(x)
        x = self.clf(x)
        return x
 ```

初始化模型并部署

 ```python
model = Net().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-2)
model
 ```

##### 3. 模型训练与测试

设置训练轮数30 轮，交替执行训练和测试流程，记录每轮的测试loss和acc

 ```python
epochs = 30
for epoch in range(epochs):
    accs, losses = [], []
    for batch_idx, (x, y) in enumerate(trainloader):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = F.cross_entropy(out, y)
        loss.backward()
        optimizer.step()

    correct = 0
    with torch.no_grad():
        testloss = 0
        for batch_idx, (x, y) in enumerate(testloader):
            x, y = x.to(device), y.to(device)
            out = model(x)
            testloss += F.cross_entropy(out, y).item()
            pred = out.max(dim=1, keepdim=True)[1]
            correct += pred.eq(y.view_as(pred)).sum().item()
        acc = correct / len(testloader.dataset)
        testloss = testloss / (batch_idx + 1)
        accs.append(acc)
        losses.append(testloss)
        print('epoch:{}, loss:{:.4f}, acc:{:.4f}'.format(epoch, testloss, acc))

 ```

##### 5.特征可视化

可视化原始图像、第一层卷积特征、第二层卷积特征

 ```python
#%%
feature1 = F.sigmoid(model.conv1(x))
# feature1 = F.avg_pool2d(feature1, kernel_size=2, stride=2)
feature2 = F.sigmoid(model.conv2(feature1))
# feature2 = F.avg_pool2d(feature2, kernel_size=2, stride=2)

n = 5
img = x.detach().cpu().numpy()[:n]
feature_map1 = feature1.detach().cpu().numpy()[:n]
feature_map2 = feature2.detach().cpu().numpy()[:n]

fig, ax = plt.subplots(3, n, figsize=(10, 10))
for i in range(n):
    # ax[0,i].axis('off')
    ax[0, i].imshow(img[i].sum(0), cmap='gray')
    # ax[1,i].axis('off')
    ax[1, i].imshow(feature_map1[i].sum(0), cmap='gray')
    # ax[2,i].axis('off')
    ax[2, i].imshow(feature_map2[i].sum(0), cmap='gray')

plt.show()
 ```

#### 五、实验结果与分析

#####  实验结果汇总

### 训练过程指标变化

| 训练轮数（epoch） | 测试损失（loss） | 测试准确率（acc） |
|------------------|-----------------|------------------|
| 1                | 2.3014          | 0.1135           |
| 5                | 0.1507          | 0.9534           |
| 10               | 0.0612          | 0.9819           |
| 20               | 0.0447          | 0.9860           |
| 30               | 0.0495          | 0.9866           |

##### 结果分析

随着训练轮数增加，测试损失持续下降，准确率逐步提升并趋于稳定，最终达到 98.6% 左右，说明模型有效拟合了 MNIST 数据集的特征，无明显过拟合

再者，通过可视化的结果可以发现，原始图像有清晰显示手写数字的轮廓和纹理，而后第一层卷积特征提取了边缘、线条等基础视觉特征，数字的轮廓特征被强化，最后第二层卷积特征更抽象，体现了 CNN 逐层提取高级特征的能力。

#### 六、实验总结

本次实验基于 PyTorch 实现 LeNet-5 模型完成 MNIST 手写数字识别，最终测试准确率约 98.6%，验证了 CNN 在图像分类中的优势。实验中，补全了卷积层、全连接层以及前向传递的逻辑代码，认识到了全连接层的输入维度和卷积层输出的特征维度不可以不匹配等问题，凸显了深度学习模型搭建中验证各层输入输出维度正确与否的重要性；特征可视化展现了 CNN 从底层边缘到高层语义特征的提取过程。


